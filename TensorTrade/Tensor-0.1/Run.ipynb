{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip tensortrade.zip\n",
    "#!unrar x LOB1_NQU22-CME_1min_2PercentSum_100PercentOrders_Overlapped_20Jun2022_19Sep2022.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get data from link\n",
    "#!wget -O data.rar https://www.dropbox.com/sh/67003kc9fekby1h/AAACExVV_b0hGQ8SdclrAX6ua/LOB1_NQU22-CME_1min_2PercentSum_100PercentOrders_Overlapped_20Jun2022_19Sep2022.rar?dl=0\n",
    "#!unrar x '/content/data.rar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test if using gpu or not # tensorflow\n",
    "# import tensorflow as tf\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# test and use gpu # pytorch\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabulate\n",
    "# !pip install stable_baselines3\n",
    "# !pip install gym\n",
    "# !pip install deprecated\n",
    "# !pip install stockstats\n",
    "# !pip install zigzag\n",
    "# !pip install unrar\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Base Libs #####################\n",
    "#from tensortrade.data.inputs import *\n",
    "from tensortrade.data.feature_engineering import FeatureEngineering\n",
    "import tensortrade.env.default as default\n",
    "import tensortrade.env.env_stocktrading_train as Environment_Train\n",
    "import tensortrade.env.env_stocktrading_test as Environment_Test\n",
    "################### Others ##########################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import optuna\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config_Path= \"E:/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/configuration.json\"\n",
    "Config_File= open(Config_Path)\n",
    "Config = json.load(Config_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nData Ghathering and Engineering\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "Data Ghathering \n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Path is : C:/Users/kasra/Downloads/Ten-Surf/Tensurf-RL/data/LOB1_NQU22-CME_1min_2PercentSum_100PercentOrders_Overlapped_20Jun2022_19Sep2022.csv\n"
     ]
    }
   ],
   "source": [
    "# see data path\n",
    "print('Data Path is :',Config['Data_Path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary feature engineering\n",
    "\n",
    "import shutil\n",
    "import ntpath\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "####################################\n",
    "\n",
    "def k_moving_average(arr, window_size=20):\n",
    "    moving_averages = []\n",
    "    i = 0\n",
    "    while i < len(arr) - window_size + 1:\n",
    "        window_average = round(np.sum(arr[i:i+window_size]) / window_size, 2)\n",
    "        moving_averages.append(window_average)\n",
    "        i += 1\n",
    "    return moving_averages\n",
    "    \n",
    "def process_data(path, ind, n, first_line, cols, dirname, level=10, k=[5,10,20,50,100], look_back=50):\n",
    "    data = [first_line]\n",
    "    with open(path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= ind[0] and i < ind[1]:\n",
    "                data.append(line)\n",
    "    ltps = []\n",
    "    for line in data[1:]:\n",
    "        splits = line.split('|')\n",
    "       \n",
    "        ltp = float(splits[cols['Candle_LastTradePrice']])\n",
    "        ltps.append(ltp)\n",
    "    multi_labels = []\n",
    "    for h in k:\n",
    "        ma = k_moving_average(ltps, h)\n",
    "        k_minus = np.array([np.nan] * (h-1) + ma)\n",
    "        k_plus = np.array(ma + [np.nan] * (h-1))\n",
    "        smoothing = (k_plus - k_minus) / k_minus\n",
    "        alpha = np.std(smoothing[~np.isnan(smoothing)]) / 2\n",
    "        labels = []\n",
    "        for s in smoothing[~np.isnan(smoothing)]:\n",
    "            if s > alpha:\n",
    "                labels.append(s)\n",
    "            elif s < -alpha:\n",
    "                labels.append(s)\n",
    "            else:\n",
    "                labels.append(s)\n",
    "        labels_str = [np.nan] * (h-1) + labels + [np.nan] * (h-1)\n",
    "        labels_str = [str(i) for i in labels_str]\n",
    "        multi_labels.append(labels_str)\n",
    "    data[0] = data[0][:-1] + '|Label1|Label2|Label3|Label4|Label5\\n'\n",
    "    for i in range(len(data)):\n",
    "        if i == 0:\n",
    "          continue\n",
    "        else:\n",
    "          splits = data[i].split('|')\n",
    "          bidprices = splits[cols['LOB_BidPrices']].split(',')\n",
    "          bidprices = [p for p in bidprices if p != ''][-level:]\n",
    "          askprices = splits[cols['LOB_AskPrices']].split(',')\n",
    "          askprices = [p for p in askprices if p != ''][:level]\n",
    "          bidvolumes = splits[cols['LOB_BidVolumes']].split(',')\n",
    "          bidvolumes = [v for v in bidvolumes if v != ''][-level:]\n",
    "          askvolumes = splits[cols['LOB_AskVolumes']].split(',')\n",
    "          askvolumes = [v for v in askvolumes if v != ''][:level]\n",
    "          splits[cols['LOB_BidPrices']] = ','.join(bidprices)\n",
    "          splits[cols['LOB_AskPrices']] = ','.join(askprices)\n",
    "          splits[cols['LOB_BidVolumes']] = ','.join(bidvolumes)\n",
    "          splits[cols['LOB_AskVolumes']] = ','.join(askvolumes)\n",
    "          splits[-1] = splits[-1][:-1]\n",
    "          splits.append(multi_labels[0][i-1])\n",
    "          splits.append(multi_labels[1][i-1])\n",
    "          splits.append(multi_labels[2][i-1])\n",
    "          splits.append(multi_labels[3][i-1])\n",
    "          splits.append(multi_labels[4][i-1] + '\\n')\n",
    "          data[i] = '|'.join(splits)\n",
    "    filename = ntpath.basename(path).split('.')[0] + 'labeled{}.csv'.format(n)\n",
    "    with open(os.path.join(dirname, 'labeled', filename), 'w') as f:\n",
    "        for line in data:\n",
    "            f.write(line)\n",
    "    corrupts = []\n",
    "    for i, line in enumerate(data):\n",
    "        splits = line.split('|')\n",
    "        bidprices = splits[cols['LOB_BidPrices']].split(',')\n",
    "        askprices = splits[cols['LOB_AskPrices']].split(',')\n",
    "        bidvolumes = splits[cols['LOB_BidVolumes']].split(',')\n",
    "        askvolumes = splits[cols['LOB_AskVolumes']].split(',')\n",
    "        if len(bidprices) < level or len(askprices) < level or '' in askprices or '' in bidprices:    # corrupt condition\n",
    "            corrupts.append(i)\n",
    "    print(len(corrupts))\n",
    "    subfiles = []\n",
    "    for i in range(len(corrupts) - 1):\n",
    "        start = corrupts[i]\n",
    "        end = corrupts[i+1]\n",
    "        if end - start - 1 >= look_back:\n",
    "            subfiles.append(data[start+1:end])\n",
    "    if (len(data) - 1 - corrupts[-1]) >= look_back:\n",
    "        subfiles.append(data[corrupts[-1]+1:])\n",
    "    total = []\n",
    "    for f in subfiles:\n",
    "        total += f\n",
    "    filename = ntpath.basename(path).split('.')[0] + '_clean_labeled_{}.csv'.format(n)\n",
    "    with open(os.path.join(dirname, 'clean_labeled', filename), 'w') as f:\n",
    "        for line in total:\n",
    "            f.write(line)\n",
    "    samplesX = []\n",
    "    samplesY = []\n",
    "    for f in subfiles:\n",
    "        for i in range(look_back-1, len(f)):\n",
    "            splits = f[i].split('|')\n",
    "            sample_labels = [float(splits[-5])+1, float(splits[-4])+1, float(splits[-3])+1, float(splits[-2])+1, float(splits[-1][:-1])+1]\n",
    "            if any([math.isnan(i) for i in sample_labels]):\n",
    "                continue\n",
    "            total_ask_prices = []\n",
    "            total_ask_volumes = []\n",
    "            total_bid_prices = []\n",
    "            total_bid_volumes = []\n",
    "            for j in range(i+1-look_back, i+1):\n",
    "                spltis = f[j].split('|')\n",
    "                total_ask_prices = total_ask_prices + splits[cols['LOB_AskPrices']].split(',')\n",
    "                total_bid_prices = total_bid_prices + splits[cols['LOB_BidPrices']].split(',')\n",
    "                if '' in total_bid_prices:\n",
    "                    print(splits[cols['LOB_BidPrices']])\n",
    "                    return splits[cols['LOB_BidPrices']]\n",
    "                total_ask_volumes = total_ask_volumes + splits[cols['LOB_AskVolumes']].split(',')\n",
    "                total_bid_volumes = total_bid_volumes + splits[cols['LOB_BidVolumes']].split(',')\n",
    "            total_ask_prices = np.array([float(i) for i in total_ask_prices])\n",
    "            total_ask_volumes = np.array([float(i) for i in total_ask_volumes])\n",
    "            total_bid_prices = np.array([float(i) for i in total_bid_prices])\n",
    "            total_bid_volumes = np.array([float(i) for i in total_bid_volumes])\n",
    "            price_mean = np.concatenate([total_ask_prices, total_bid_prices]).mean()\n",
    "            price_std = np.concatenate([total_ask_prices, total_bid_prices]).std()\n",
    "            volume_mean = np.concatenate([total_ask_volumes, total_bid_volumes]).mean()\n",
    "            volume_std = np.concatenate([total_ask_volumes, total_bid_volumes]).std()\n",
    "            total_ask_prices = (total_ask_prices - price_mean) / price_std\n",
    "            total_ask_volumes = (total_ask_volumes - volume_mean) / volume_std\n",
    "            total_bid_prices = (total_bid_prices - price_mean) / price_std\n",
    "            total_bid_volumes = (total_bid_volumes - volume_mean) / volume_std\n",
    "            total = np.stack([total_ask_prices, total_bid_prices, total_ask_volumes, total_bid_volumes]).T\n",
    "            total = total.reshape((look_back, -1))\n",
    "            samplesX.append(total)\n",
    "           \n",
    "            samplesY.append(sample_labels)\n",
    "    X_name = ntpath.basename(path).split('.')[0] + 'X{}.npy'.format(n)\n",
    "    y_name = ntpath.basename(path).split('.')[0] + 'y{}.npy'.format(n)\n",
    "    with open(os.path.join(dirname, 'numpy', X_name), 'wb') as f:\n",
    "        np.save(f, np.array(samplesX).reshape(-1, look_back, level*4, 1))\n",
    "    with open(os.path.join(dirname, 'numpy', y_name), 'wb') as f:\n",
    "        np.save(f, np.array(samplesY))\n",
    "\n",
    "def prepare_data_2(path, level=10, k=[5,10,20,50,100], look_back=50):\n",
    "    dirname = ntpath.basename(path).split('.')[0] + '_processed'\n",
    "    count = 0\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if count == 0:\n",
    "                cols = line.split('|')\n",
    "                cols[-1] = cols[-1][:-1]\n",
    "                cols = {cols[i]:i for i in range(len(cols))}\n",
    "                first_line = line\n",
    "            count += 1\n",
    "   \n",
    "    n = (count // 45000) + 1\n",
    "    \n",
    "    inds = []\n",
    "    for i in range(n):\n",
    "        if (count - i*45000) > 45000:\n",
    "            if i == 0:\n",
    "                inds.append((1, (i+1)*45000))\n",
    "            else:\n",
    "                inds.append((i*45000, (i+1)*45000))\n",
    "        else:\n",
    "            inds.append((i*45000, count))\n",
    "    try:\n",
    "        shutil.rmtree(dirname)\n",
    "        print('Removing old directory and creating a new one')\n",
    "    except:\n",
    "        print('No such directory')\n",
    "        print('Creating new directory')\n",
    "        \n",
    "    os.mkdir(dirname)\n",
    "    os.mkdir(os.path.join(dirname, 'labeled'))\n",
    "    os.mkdir(os.path.join(dirname, 'clean_labeled'))\n",
    "    os.mkdir(os.path.join(dirname, 'numpy'))\n",
    "\n",
    "    for i, ind in enumerate(inds):\n",
    "        process_data(path=path, ind=ind, n=i, first_line=first_line, cols=cols, dirname=dirname, level=level, k=k, look_back=look_back)\n",
    "\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing old directory and creating a new one\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kasra\\AppData\\Local\\Temp\\ipykernel_5968\\2734505880.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  total_ask_volumes = (total_ask_volumes - volume_mean) / volume_std\n",
      "C:\\Users\\kasra\\AppData\\Local\\Temp\\ipykernel_5968\\2734505880.py:135: RuntimeWarning: invalid value encountered in divide\n",
      "  total_bid_volumes = (total_bid_volumes - volume_mean) / volume_std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1618\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\numpy\\core\\_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\numpy\\core\\_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\numpy\\core\\_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "prepare_data_2(Config['Data_Path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name= ['DateTime','open', 'high', 'low',\n",
    "       'close', 'Candle_LastTradePrice', 'volume',\n",
    "       'bid_volume', 'ask_volume',\n",
    "       'numTrades', 'bid_number',\n",
    "       'ask_number', 'askbidDiffHigh',\n",
    "       'askbidDifflow', 'askbidnumTradesDiffHigh',\n",
    "       'askbidnumTradesDifflow', 'UpDownvolDiffHigh',\n",
    "       'UpDownvolDifflow', 'ATR', 'sum_lob_bid', 'sum_lob_ask',\n",
    "       'LOB_SumBidTick', 'LOB_SumAskTick', 'lob_bid_price', 'lob_bid_volume',\n",
    "       'lob_ask_price', 'lob_ask_volume', 'VAP_Prices', 'VAP_Volumes',\n",
    "       'VAP_AskVolumes', 'VAP_BidVolumes', 'VAP_NumberOfTrades',\n",
    "       'VAP_TotalVolume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1=pd.read_csv('LOB1_NQU22-CME_1min_2PercentSum_100PercentOrders_Overlapped_20Jun2022_19Sep2022_processed/clean_labeled/LOB1_NQU22-CME_1min_2PercentSum_100PercentOrders_Overlapped_20Jun2022_19Sep2022_clean_labeled_0.csv',names= column_name, usecols = [i for i in range(33)], delimiter=\"|\")\n",
    "D2=pd.read_csv('LOB1_NQU22-CME_1min_2PercentSum_100PercentOrders_Overlapped_20Jun2022_19Sep2022_processed/clean_labeled/LOB1_NQU22-CME_1min_2PercentSum_100PercentOrders_Overlapped_20Jun2022_19Sep2022_clean_labeled_1.csv',names= column_name, usecols = [i for i in range(33)], delimiter=\"|\")\n",
    "D3=pd.read_csv('LOB1_NQU22-CME_1min_2PercentSum_100PercentOrders_Overlapped_20Jun2022_19Sep2022_processed/clean_labeled/LOB1_NQU22-CME_1min_2PercentSum_100PercentOrders_Overlapped_20Jun2022_19Sep2022_clean_labeled_2.csv',names= column_name, usecols = [i for i in range(33)], delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data= pd.concat([D1,D2,D3])\n",
    "Data[\"DateTime\"] = pd.to_datetime(Data[\"DateTime\"])\n",
    "Data.set_index([\"DateTime\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Candle_LastTradePrice</th>\n",
       "      <th>volume</th>\n",
       "      <th>bid_volume</th>\n",
       "      <th>ask_volume</th>\n",
       "      <th>numTrades</th>\n",
       "      <th>bid_number</th>\n",
       "      <th>...</th>\n",
       "      <th>lob_bid_price</th>\n",
       "      <th>lob_bid_volume</th>\n",
       "      <th>lob_ask_price</th>\n",
       "      <th>lob_ask_volume</th>\n",
       "      <th>VAP_Prices</th>\n",
       "      <th>VAP_Volumes</th>\n",
       "      <th>VAP_AskVolumes</th>\n",
       "      <th>VAP_BidVolumes</th>\n",
       "      <th>VAP_NumberOfTrades</th>\n",
       "      <th>VAP_TotalVolume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-19 23:59:00</th>\n",
       "      <td>11385.5</td>\n",
       "      <td>11385.50</td>\n",
       "      <td>11378.00</td>\n",
       "      <td>11379.25</td>\n",
       "      <td>11378.50</td>\n",
       "      <td>129</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>123</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>11383.00,11383.25,11383.50,11383.75,11384.00,1...</td>\n",
       "      <td>1,2,1,1,1,2,2,1,1,1</td>\n",
       "      <td>11378.25,11378.50,11378.75,11379.00,11379.25,1...</td>\n",
       "      <td>2,1,1,1,2,1,2,2,2,1</td>\n",
       "      <td>11378.00,11378.25,11378.50,11378.75,11379.00,1...</td>\n",
       "      <td>3,3,12,32,15,17,14,5,8,1,2,2,1,2,1,2,1,4,1,1,1,1,</td>\n",
       "      <td>0,0,3,20,9,11,8,2,7,1,0,0,0,0,0,0,0,2,0,0,0,0,</td>\n",
       "      <td>3,3,9,12,6,6,6,3,1,0,2,2,1,2,1,2,1,2,1,1,1,1,</td>\n",
       "      <td>3,3,12,29,14,17,14,5,6,1,2,2,1,2,1,2,1,4,1,1,1,1,</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-20 00:00:00</th>\n",
       "      <td>11378.5</td>\n",
       "      <td>11387.25</td>\n",
       "      <td>11369.50</td>\n",
       "      <td>11381.25</td>\n",
       "      <td>11382.00</td>\n",
       "      <td>343</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>327</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>11384.50,11384.75,11385.00,11385.25,11385.50,1...</td>\n",
       "      <td>2,1,1,1,1,2,2,3,2,1</td>\n",
       "      <td>11370.00,11370.25,11370.50,11370.75,11371.00,1...</td>\n",
       "      <td>1,1,2,2,2,1,1,2,1,1</td>\n",
       "      <td>11369.50,11369.75,11370.00,11370.25,11370.50,1...</td>\n",
       "      <td>1,1,4,1,1,5,1,1,2,1,10,6,7,3,13,2,2,3,2,2,3,2,...</td>\n",
       "      <td>0,0,1,1,1,1,0,0,1,1,0,3,3,0,10,1,1,2,2,1,1,2,2...</td>\n",
       "      <td>1,1,3,0,0,4,1,1,1,0,10,3,4,3,3,1,1,1,0,1,2,0,2...</td>\n",
       "      <td>1,1,4,1,1,5,1,1,2,1,10,6,7,3,10,2,2,3,2,2,3,2,...</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-20 00:01:00</th>\n",
       "      <td>11382.0</td>\n",
       "      <td>11397.25</td>\n",
       "      <td>11379.75</td>\n",
       "      <td>11395.50</td>\n",
       "      <td>11397.25</td>\n",
       "      <td>282</td>\n",
       "      <td>84</td>\n",
       "      <td>198</td>\n",
       "      <td>255</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>11394.25,11394.50,11394.75,11395.00,11395.25,1...</td>\n",
       "      <td>4,4,3,1,1,3,4,3,1,2</td>\n",
       "      <td>11380.25,11380.50,11380.75,11381.00,11381.25,1...</td>\n",
       "      <td>1,1,14,1,1,1,1,1,1,1</td>\n",
       "      <td>11379.75,11380.25,11380.50,11380.75,11381.00,1...</td>\n",
       "      <td>1,4,3,26,2,4,1,2,7,3,3,2,3,4,3,7,3,4,9,4,3,2,2...</td>\n",
       "      <td>0,0,1,25,0,4,0,0,4,0,2,1,2,0,0,5,2,0,9,2,2,1,1...</td>\n",
       "      <td>1,4,2,1,2,0,1,2,3,3,1,1,1,4,3,2,1,4,0,2,1,1,1,...</td>\n",
       "      <td>1,4,3,8,2,4,1,2,7,3,3,2,3,3,3,7,3,4,9,4,3,2,2,...</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open      high       low     close  \\\n",
       "DateTime                                                     \n",
       "2022-06-19 23:59:00  11385.5  11385.50  11378.00  11379.25   \n",
       "2022-06-20 00:00:00  11378.5  11387.25  11369.50  11381.25   \n",
       "2022-06-20 00:01:00  11382.0  11397.25  11379.75  11395.50   \n",
       "\n",
       "                     Candle_LastTradePrice  volume  bid_volume  ask_volume  \\\n",
       "DateTime                                                                     \n",
       "2022-06-19 23:59:00               11378.50     129          66          63   \n",
       "2022-06-20 00:00:00               11382.00     343         171         172   \n",
       "2022-06-20 00:01:00               11397.25     282          84         198   \n",
       "\n",
       "                     numTrades  bid_number  ...  \\\n",
       "DateTime                                    ...   \n",
       "2022-06-19 23:59:00        123          66  ...   \n",
       "2022-06-20 00:00:00        327         170  ...   \n",
       "2022-06-20 00:01:00        255          83  ...   \n",
       "\n",
       "                                                         lob_bid_price  \\\n",
       "DateTime                                                                 \n",
       "2022-06-19 23:59:00  11383.00,11383.25,11383.50,11383.75,11384.00,1...   \n",
       "2022-06-20 00:00:00  11384.50,11384.75,11385.00,11385.25,11385.50,1...   \n",
       "2022-06-20 00:01:00  11394.25,11394.50,11394.75,11395.00,11395.25,1...   \n",
       "\n",
       "                          lob_bid_volume  \\\n",
       "DateTime                                   \n",
       "2022-06-19 23:59:00  1,2,1,1,1,2,2,1,1,1   \n",
       "2022-06-20 00:00:00  2,1,1,1,1,2,2,3,2,1   \n",
       "2022-06-20 00:01:00  4,4,3,1,1,3,4,3,1,2   \n",
       "\n",
       "                                                         lob_ask_price  \\\n",
       "DateTime                                                                 \n",
       "2022-06-19 23:59:00  11378.25,11378.50,11378.75,11379.00,11379.25,1...   \n",
       "2022-06-20 00:00:00  11370.00,11370.25,11370.50,11370.75,11371.00,1...   \n",
       "2022-06-20 00:01:00  11380.25,11380.50,11380.75,11381.00,11381.25,1...   \n",
       "\n",
       "                           lob_ask_volume  \\\n",
       "DateTime                                    \n",
       "2022-06-19 23:59:00   2,1,1,1,2,1,2,2,2,1   \n",
       "2022-06-20 00:00:00   1,1,2,2,2,1,1,2,1,1   \n",
       "2022-06-20 00:01:00  1,1,14,1,1,1,1,1,1,1   \n",
       "\n",
       "                                                            VAP_Prices  \\\n",
       "DateTime                                                                 \n",
       "2022-06-19 23:59:00  11378.00,11378.25,11378.50,11378.75,11379.00,1...   \n",
       "2022-06-20 00:00:00  11369.50,11369.75,11370.00,11370.25,11370.50,1...   \n",
       "2022-06-20 00:01:00  11379.75,11380.25,11380.50,11380.75,11381.00,1...   \n",
       "\n",
       "                                                           VAP_Volumes  \\\n",
       "DateTime                                                                 \n",
       "2022-06-19 23:59:00  3,3,12,32,15,17,14,5,8,1,2,2,1,2,1,2,1,4,1,1,1,1,   \n",
       "2022-06-20 00:00:00  1,1,4,1,1,5,1,1,2,1,10,6,7,3,13,2,2,3,2,2,3,2,...   \n",
       "2022-06-20 00:01:00  1,4,3,26,2,4,1,2,7,3,3,2,3,4,3,7,3,4,9,4,3,2,2...   \n",
       "\n",
       "                                                        VAP_AskVolumes  \\\n",
       "DateTime                                                                 \n",
       "2022-06-19 23:59:00     0,0,3,20,9,11,8,2,7,1,0,0,0,0,0,0,0,2,0,0,0,0,   \n",
       "2022-06-20 00:00:00  0,0,1,1,1,1,0,0,1,1,0,3,3,0,10,1,1,2,2,1,1,2,2...   \n",
       "2022-06-20 00:01:00  0,0,1,25,0,4,0,0,4,0,2,1,2,0,0,5,2,0,9,2,2,1,1...   \n",
       "\n",
       "                                                        VAP_BidVolumes  \\\n",
       "DateTime                                                                 \n",
       "2022-06-19 23:59:00      3,3,9,12,6,6,6,3,1,0,2,2,1,2,1,2,1,2,1,1,1,1,   \n",
       "2022-06-20 00:00:00  1,1,3,0,0,4,1,1,1,0,10,3,4,3,3,1,1,1,0,1,2,0,2...   \n",
       "2022-06-20 00:01:00  1,4,2,1,2,0,1,2,3,3,1,1,1,4,3,2,1,4,0,2,1,1,1,...   \n",
       "\n",
       "                                                    VAP_NumberOfTrades  \\\n",
       "DateTime                                                                 \n",
       "2022-06-19 23:59:00  3,3,12,29,14,17,14,5,6,1,2,2,1,2,1,2,1,4,1,1,1,1,   \n",
       "2022-06-20 00:00:00  1,1,4,1,1,5,1,1,2,1,10,6,7,3,10,2,2,3,2,2,3,2,...   \n",
       "2022-06-20 00:01:00  1,4,3,8,2,4,1,2,7,3,3,2,3,3,3,7,3,4,9,4,3,2,2,...   \n",
       "\n",
       "                     VAP_TotalVolume  \n",
       "DateTime                              \n",
       "2022-06-19 23:59:00              129  \n",
       "2022-06-20 00:00:00              343  \n",
       "2022-06-20 00:01:00              282  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOB Data\n",
    "# LOB_Data_test_unnormal.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nTrain Test and Optimize\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "Train Test and Optimize\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to create environment\n",
    "\n",
    "def create_env_train(data,price,date,config):\n",
    "\n",
    "    env= Environment_Train.StockTradingEnv_Train(data,price,date,config)\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to create test environment\n",
    "\n",
    "def create_env_test(data,price,date,config):\n",
    "\n",
    "    env= Environment_Test.StockTradingEnv_Test(data,price,date,config)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import agents\n",
    "from stable_baselines3 import A2C,DQN,PPO\n",
    "# import environment checker\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if environment meet gym policy\n",
    "# env_checker.check_env(env_train , warn=False, skip_render_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# from torch.utils import data\n",
    "# from torchinfo import summary\n",
    "# from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "# from stable_baselines3.common.policies import ActorCriticPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "#from torch import nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int ):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,4), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,4), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "             nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        # Compute shape by doing one forward pass\n",
    "        # with th.no_grad():\n",
    "        #     n_flatten = self.inp3(\n",
    "        #         th.as_tensor(observation_space.sample()[None]).float()\n",
    "        #     ).shape[1]\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, features_dim)\n",
    "\n",
    "    def forward(self, x: th.Tensor) -> th.Tensor:\n",
    "        \n",
    "        # return self.linear(self.lstm(self.cnn(observations)))\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "       \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        # forecast_y = torch.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=49),\n",
    "    net_arch=[dict(vf=[64], pi=[64])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main(config, trial=None):\n",
    "    \n",
    "    if config['RUNNING_MODE'] == 'optimize':\n",
    "        config = select_params_value(trial, config)\n",
    "\n",
    "    # Data Feature Engineering\n",
    "    preProcessedData = FeatureEngineering(Data,Config['Feature_engineering'])\n",
    "    LOB_Data_train,LOB_Data_test,LOB_Data_train_unnormal,LOB_Data_test_unnormal,LOB_Train_dates,LOB_Test_dates = preProcessedData.add_all_features()\n",
    "\n",
    "    # make train data\n",
    "    Time_Data = LOB_Train_dates # just time column\n",
    "    Data=LOB_Data_train\n",
    "    Price_Data = pd.DataFrame(LOB_Data_train_unnormal[['open','high','low','close']]) # just price related columns\n",
    "\n",
    "    # make test data\n",
    "    Data_Test=LOB_Data_test\n",
    "    Price_Data_Test = pd.DataFrame(LOB_Data_test_unnormal[['open','high','low','close']]) # just price related columns\n",
    "    #Price_Data_Test.reset_index(drop=True,inplace=True)\n",
    "    Time_Data_Test = LOB_Test_dates  # just time column\n",
    "\n",
    "    # Number of objectives\n",
    "    obj_no = config['number_of_objectives']\n",
    "\n",
    "    # create train env\n",
    "    env_train= create_env_train(Data.copy(),Price_Data.copy(),Time_Data,config['env_config_train'])\n",
    "\n",
    "    # create test env\n",
    "    env_test =  create_env_test(Data_Test.copy(),Price_Data_Test.copy(),Time_Data_Test,config['env_config_test'])\n",
    "\n",
    "    # create RL model\n",
    "    #policy_kwargs = dict(net_arch=[8,16, dict(vf=[32,64,128,256], pi=[32,64,128,256])])\n",
    "    RL_model = A2C(config['A2C_PARAMS']['net_arch'], env_train, verbose=1,device=device,\n",
    "    learning_rate=config['A2C_PARAMS']['learning_rate'], policy_kwargs=policy_kwargs,seed=config['A2C_PARAMS']['SEED'])\n",
    "    RL_model.learn(total_timesteps=config['A2C_PARAMS']['TOTAL_TIMESTEPS'])\n",
    "    #RL_model.save(\"RlSurf-A2C\")\n",
    "\n",
    "    # test RL model on test data\n",
    "    obs = env_test.get_state()    #~ we should not reset env manullay\n",
    "    number_candle=0 \n",
    "\n",
    "    while True: \n",
    "    \n",
    "        action, _states = RL_model.predict(obs,deterministic=True)\n",
    "    \n",
    "        number_candle+=1\n",
    "        obs, rewards, done, info = env_test.step(action)\n",
    "\n",
    "        if done:\n",
    "\n",
    "            if env_test.day_index>= len(env_test.day_indices)-1:\n",
    "                    print(\"Account Balance Is : \", info['account_status'])\n",
    "                    \n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                print('episode(Day) is : ',env_test.episode)\n",
    "                env_test.reset()\n",
    "\n",
    "    if config['RUNNING_MODE'] in ('backtest','train') :\n",
    "            print(env_test.tradeslist)\n",
    "            env_test.show_results()\n",
    "\n",
    "    elif Config['RUNNING_MODE'] == 'optimize':\n",
    "            cum_pnl,maxdrawdown= env_test.show_results()\n",
    "            if obj_no == 1:\n",
    "                return cum_pnl\n",
    "            elif obj_no == 2:\n",
    "                return cum_pnl, maxdrawdown\n",
    "\n",
    "############## change config for each trial               \n",
    "def select_params_value(trial, config):\n",
    "    \n",
    "    optimization_params = json.load(open('E:/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/optimization_params.json'))\n",
    "    for key, value in optimization_params.items():\n",
    "        if key.startswith('_'):\n",
    "            continue\n",
    "      \n",
    "        param_value = getattr(trial, value[0])(key, **value[1])\n",
    "\n",
    "        if key in config['A2C_PARAMS'].keys():\n",
    "            config['A2C_PARAMS'][key] = param_value\n",
    "\n",
    "        elif key in config['env_config_train'].keys():\n",
    "            config['env_config_train'][key] = param_value\n",
    "\n",
    "        elif key in config['env_config_test'].keys():\n",
    "            config['env_config_test'][key] = param_value\n",
    "        \n",
    "        elif key in config['Feature_engineering'].keys():\n",
    "            config['Feature_engineering'][key] = param_value\n",
    "\n",
    "        else:\n",
    "            raise Exception('Undefined parameter ' + key)\n",
    "            \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-26 10:56:00,715]\u001b[0m A new study created in RDB with name: optimization1\u001b[0m\n",
      "c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [1, 20] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 19].\n",
      "  warnings.warn(\n",
      "c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [1, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [1, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.842   |\n",
      "|    explained_variance | 0.366    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.961    |\n",
      "|    value_loss         | 1.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.765   |\n",
      "|    explained_variance | 0.152    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.3     |\n",
      "|    value_loss         | 0.644    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.838   |\n",
      "|    explained_variance | 0.139    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.15     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.953   |\n",
      "|    explained_variance | 0.0375   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    value_loss         | 3.88     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-10-26 10:57:01,897]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\kasra\\AppData\\Local\\Temp\\ipykernel_14816\\3828216677.py\", line 19, in <lambda>\n",
      "    lambda trial: Main(Config, trial), n_trials=100, n_jobs=1, timeout=None)\n",
      "  File \"C:\\Users\\kasra\\AppData\\Local\\Temp\\ipykernel_14816\\3108804324.py\", line 17, in Main\n",
      "    RL_model.learn(total_timesteps=config['A2C_PARAMS']['TOTAL_TIMESTEPS'])\n",
      "  File \"c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py\", line 197, in learn\n",
      "    return super().learn(\n",
      "  File \"c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\", line 267, in learn\n",
      "    self.train()\n",
      "  File \"c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py\", line 170, in train\n",
      "    th.nn.utils.clip_grad_norm_(self.policy.parameters(), self.max_grad_norm)\n",
      "  File \"c:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 42, in clip_grad_norm_\n",
      "    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Tensurf-RL\\tensurfrl\\TensorTrade\\Tensor-0.1\\Run.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mload_study(study_name\u001b[39m=\u001b[39mstudy_name, storage\u001b[39m=\u001b[39mstorage)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m- - - - - - Optimization study loaded - - - - - -\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     study\u001b[39m.\u001b[39;49moptimize(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39mlambda\u001b[39;49;00m trial: Main(Config, trial), n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, timeout\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m       Main(Config)\n",
      "File \u001b[1;32mc:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32me:\\Tensurf-RL\\tensurfrl\\TensorTrade\\Tensor-0.1\\Run.ipynb Cell 31\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mload_study(study_name\u001b[39m=\u001b[39mstudy_name, storage\u001b[39m=\u001b[39mstorage)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m- - - - - - Optimization study loaded - - - - - -\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     study\u001b[39m.\u001b[39moptimize(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m trial: Main(Config, trial), n_trials\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m       Main(Config)\n",
      "\u001b[1;32me:\\Tensurf-RL\\tensurfrl\\TensorTrade\\Tensor-0.1\\Run.ipynb Cell 31\u001b[0m in \u001b[0;36mMain\u001b[1;34m(config, trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#~ create RL model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#policy_kwargs = dict(net_arch=[8,16, dict(vf=[32,64,128,256], pi=[32,64,128,256])])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m RL_model \u001b[39m=\u001b[39m A2C(config[\u001b[39m'\u001b[39m\u001b[39mA2C_PARAMS\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mnet_arch\u001b[39m\u001b[39m'\u001b[39m], env_train, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,device\u001b[39m=\u001b[39mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m learning_rate\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mA2C_PARAMS\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m], policy_kwargs\u001b[39m=\u001b[39mpolicy_kwargs,seed\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mA2C_PARAMS\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mSEED\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m RL_model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mA2C_PARAMS\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mTOTAL_TIMESTEPS\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#RL_model.save(\"RlSurf-A2C\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#~ test RL on test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Tensurf-RL/tensurfrl/TensorTrade/Tensor-0.1/Run.ipynb#X42sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m obs \u001b[39m=\u001b[39m env_test\u001b[39m.\u001b[39mget_state()    \u001b[39m#~ we should not reset env manullay\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:197\u001b[0m, in \u001b[0;36mA2C.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    185\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    186\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    195\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mA2C\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 197\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    198\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    199\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    200\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    201\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[0;32m    202\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[0;32m    203\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[0;32m    204\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    205\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[0;32m    206\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    207\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:267\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mrecord(\u001b[39m\"\u001b[39m\u001b[39mtime/total_timesteps\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps, exclude\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    265\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdump(step\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps)\n\u001b[1;32m--> 267\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    269\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[0;32m    271\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:170\u001b[0m, in \u001b[0;36mA2C.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    169\u001b[0m     \u001b[39m# Clip grad norm\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m     th\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mclip_grad_norm_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mparameters(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_grad_norm)\n\u001b[0;32m    171\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    173\u001b[0m explained_var \u001b[39m=\u001b[39m explained_variance(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrollout_buffer\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mflatten(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrollout_buffer\u001b[39m.\u001b[39mreturns\u001b[39m.\u001b[39mflatten())\n",
      "File \u001b[1;32mc:\\Users\\kasra\\.conda\\envs\\Ai\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:42\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[0;32m     40\u001b[0m     total_norm \u001b[39m=\u001b[39m norms[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(norms) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mmax(torch\u001b[39m.\u001b[39mstack(norms))\n\u001b[0;32m     41\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     total_norm \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(torch\u001b[39m.\u001b[39;49mstack([torch\u001b[39m.\u001b[39;49mnorm(p\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mdetach(), norm_type)\u001b[39m.\u001b[39;49mto(device) \u001b[39mfor\u001b[39;49;00m p \u001b[39min\u001b[39;49;00m parameters]), norm_type)\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m error_if_nonfinite \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39mlogical_or(total_norm\u001b[39m.\u001b[39misnan(), total_norm\u001b[39m.\u001b[39misinf()):\n\u001b[0;32m     44\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m     45\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe total norm of order \u001b[39m\u001b[39m{\u001b[39;00mnorm_type\u001b[39m}\u001b[39;00m\u001b[39m for gradients from \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     46\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     47\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     48\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mset `error_if_nonfinite=False`\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start time\n",
    "start = time.time()\n",
    "\n",
    "# check run mode and make study with optuna\n",
    "if Config['RUNNING_MODE'] == 'optimize':\n",
    "    \n",
    "    study_name = Config['study_name']\n",
    "    storage = 'sqlite:///optimization_results.sqlite'\n",
    "    try:\n",
    "        obj_no = Config['number_of_objectives']\n",
    "        directions = [\"maximize\",\"minimize\"] \n",
    "\n",
    "        if obj_no == 1:\n",
    "            study = optuna.create_study(direction=\"maximize\", study_name=study_name, storage=storage)\n",
    "        else:\n",
    "            study = optuna.create_study(directions=directions , study_name=study_name, storage=storage)\n",
    "    except:\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "        print('- - - - - - Optimization study loaded - - - - - -')\n",
    "    study.optimize(\n",
    "        lambda trial: Main(Config, trial), n_trials=100, n_jobs=1, timeout=None)\n",
    "        \n",
    "else:\n",
    "      Main(Config)\n",
    "\n",
    "# total elapsed time\n",
    "print(f'Runtime: {round(time.time() - start)} secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alt Env Test\n",
    "\n",
    "# ################ Libs ##############\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from gym.utils import seeding\n",
    "# import gym\n",
    "# from gym import spaces\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from stockstats import StockDataFrame \n",
    "# from zigzag import peak_valley_pivots\n",
    "# from tabulate import tabulate\n",
    "# from scipy.signal import argrelextrema\n",
    "# ################################\n",
    "\n",
    "# \"\"\"\n",
    "# A custom stock trading environment based on OpenAI gym (Test Env)\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# class ENVV(gym.Env):\n",
    "\n",
    "#     def __init__(self,df, price_data, date, config):\n",
    "\n",
    "#         self.data = df\n",
    "#         self.config = config\n",
    "#         self.price_data = price_data\n",
    "#         self.price_data['action'] = 0   # make action column in price data to save each action\n",
    "#         self.atr = StockDataFrame.retype(price_data.copy())['atr'] # calculate atr indicator\n",
    "#         self.timesteps = self.config[\"TIMESTEPS\"] \n",
    "#         self.action_space = spaces.Discrete(3) # define action space\n",
    "#         self.state_space = (self.action_space.n * config[\"USE_LAST_ACTION\"]) + 2 * config[ \n",
    "#             \"USE_CURRENT_PNL\"] + self.timesteps * len(df.columns)  # define states space\n",
    "        \n",
    "#         self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(1,100,49)) # don't change this line !!!\n",
    "#         self.num_of_shares = config[\"MAX_NUM_SHARES\"]\n",
    "#         self.date = date # date of dataframe\n",
    "\n",
    "#         daily = pd.to_datetime([pd.to_datetime(x) - pd.Timedelta(hours=15) for x in self.date]).floor('d') # specify day indexes\n",
    "#         daily = pd.DataFrame(daily, columns=['date'])\n",
    "#         self.day_indices = [x.total_seconds() for x in daily['date'] - daily['date'].shift(1)]\n",
    "#         self.day_indices = [i for i, v in enumerate(self.day_indices) if v != 0]\n",
    "#         self.day_indices = self.day_indices[1:] \n",
    "#         self.day_indices[0] = self.timesteps \n",
    "\n",
    "#         self.current_point = self.day_indices[0] \n",
    "#         self.day_index = 0 \n",
    "#         self.current_position = 0\n",
    "#         self.last_action = 0\n",
    "#         self.entry_index = 0\n",
    "       \n",
    "#         self.spread_cost = config[\"Exchange_Commission\"]    # set exchange commission\n",
    "        \n",
    "#         self.base_account = config[\"INITIAL_ACCOUNT_BALANCE\"]\n",
    "\n",
    "#         self.episode = 0\n",
    "#         self.account = self.base_account\n",
    "#         # memorize all the total balance change\n",
    "#         self.entry_date = None\n",
    "#         self.tradeslist = pd.DataFrame( \n",
    "#             columns=['entry date', 'entry price', 'action', 'exit date', 'exit price', 'pnl','cum_pnl', 'mae', 'mpe','exit mode','sl','tp'])\n",
    "#         self.tradeslist.loc[0] = [self.date[0],0, 0,\n",
    "#         self.date[0], 0,0, self.account, 0, 0, 0, 0, 0]\n",
    "#         self._seed()\n",
    "#         self.positives = 0    # ?\n",
    "#         self.negatives = 0    # ?\n",
    "\n",
    "#         self.sl_mode= config[\"SL_mode\"]\n",
    "#         self.sl_value= config[\"STOP_LOSS\"]                                \n",
    "#         self.scipy_neighborhood=  config[\"Scipy_neighborhood\"]\n",
    "#         self.R2R = config[\"R2R\"]\n",
    "#         self.stop_loss= 0\n",
    "#         self.take_profit = -1\n",
    "#         self.sltp_flag= False\n",
    "\n",
    "#     '''\n",
    "#     func to determine stop loss base on zigzag indicator\n",
    "\n",
    "#     '''\n",
    "#     def find_pivots(self, action):\n",
    "\n",
    "#         pivot_param = .002\n",
    "#         step = .0005\n",
    "#         lookback = self.config['lookback']\n",
    "#         data = self.price_data['close'][max(0, self.current_point - lookback):self.current_point].to_numpy()\n",
    "#         pivots = peak_valley_pivots(data, pivot_param, -pivot_param)\n",
    "#         condition = -action\n",
    "#         current_price = self.price_data['close'][self.current_point - 1]\n",
    "#         if np.sum(pivots == condition) and condition * current_price < condition * data[\n",
    "#             np.where(pivots == condition)[0][-1]]:\n",
    "#             return abs(current_price - data[np.where(pivots == condition)[0][-1]])\n",
    "#         else:\n",
    "#             return self.config[\"STOP_LOSS_COEF\"] * self.atr[self.current_point]     \n",
    "\n",
    "#     '''\n",
    "#     func to get date\n",
    "\n",
    "#     '''\n",
    "#     def get_date(self):\n",
    "        \n",
    "#         try:\n",
    "#             return self.date[self.current_point]\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#     '''\n",
    "#     func to get price\n",
    "\n",
    "#     '''\n",
    "#     def get_price(self, point):\n",
    "\n",
    "#         price_type = self.config[\"PRICE_CALCULATION_TYPE\"]\n",
    "\n",
    "#         if price_type == 'mid':\n",
    "#             return self.price_data.loc[point, ['open', 'low', 'high', 'close']].mean()\n",
    "#         elif price_type == 'close':\n",
    "#             return self.price_data.loc[point,'close']\n",
    "#         elif price_type=='open':\n",
    "#             return self.price_data.iloc[point]['open']\n",
    "\n",
    "#     '''\n",
    "#     func to calculate PNL\n",
    "\n",
    "#     '''\n",
    "#     def calculate_pnl(self, action, previous_price, current_price, spread=True):\n",
    "\n",
    "#         if  action==0:  # if action be 0(hold) pnl will be 0 \n",
    "#             return 0\n",
    "\n",
    "#         diff_price = current_price - previous_price\n",
    "\n",
    "#         if spread:\n",
    "#             return (action * diff_price - self.spread_cost * spread ) * self.num_of_shares\n",
    "#         else:\n",
    "#             return (action * diff_price ) * self.num_of_shares\n",
    "             \n",
    "#     '''\n",
    "#     func to calculate reward\n",
    "\n",
    "#     '''\n",
    "#     def calculate_reward(self,current_position, new_action, current_point, previous_point):\n",
    "\n",
    "#         previous_price = self.get_price(previous_point)\n",
    "#         current_price = self.get_price(current_point)\n",
    "#         next_price = self.get_price(current_point + 1)\n",
    "#         profit_loss = self.calculate_pnl(current_position, previous_price, current_price)\n",
    "#         profit_loss = (profit_loss if (new_action!=0) else 0)    # ignore profit_loss if new action be same as previous action\n",
    "#         min_price = self.price_data['low'][previous_point:current_point].min()\n",
    "#         max_price = self.price_data['high'][previous_point:current_point].max()\n",
    "        \n",
    "#         if current_position == 1:\n",
    "#             MAE = self.calculate_pnl(current_position, previous_price, min_price, spread=False)\n",
    "#             MPE = self.calculate_pnl(current_position, max_price, current_price, spread=False)\n",
    "#         elif current_position == -1:\n",
    "#             MAE = self.calculate_pnl(current_position, previous_price, max_price, spread=False)\n",
    "#             MPE = self.calculate_pnl(current_position, min_price, current_price, spread=False)\n",
    "#         else:\n",
    "#             MAE = 0\n",
    "#             MPE = 0\n",
    "\n",
    "#         return profit_loss, MAE, MPE\n",
    "\n",
    "#     '''\n",
    "#     func to calculate account PNL in percent\n",
    "\n",
    "#     '''\n",
    "#     def calculate_benefit(self):\n",
    "\n",
    "#         action = self.current_position\n",
    "#         profit_loss = self.calculate_pnl(action, self.get_price(self.entry_index),\n",
    "#                                          self.get_price(self.current_point))\n",
    "#         acount_pnl_percentage = (self.base_account + profit_loss) / self.base_account\n",
    "\n",
    "#         return (acount_pnl_percentage - 1), profit_loss\n",
    "\n",
    "#     '''\n",
    "#     func to get environment state\n",
    "\n",
    "#     '''\n",
    "#     def get_state(self):\n",
    "\n",
    "#         s_ = self.data.iloc[self.current_point - self.timesteps:self.current_point , :]\n",
    "#         st= s_.values.reshape(1,100,49)\n",
    "       \n",
    "#         return st\n",
    "\n",
    "#     '''\n",
    "#     func calculate sl tp based on swing\n",
    "\n",
    "#     '''\n",
    "#     def calculate_sltp(self, current_index, action, fill_price):\n",
    "        \n",
    "#         minimum_risk = self.sl_value\n",
    "#         self.risk = self.sl_value\n",
    "#         if self.sl_mode == 'fixed':  #fix mode\n",
    "#             if action == 1:\n",
    "#                 self.stop_loss = fill_price - action * self.risk\n",
    "#                 self.take_profit = fill_price + action * self.risk \n",
    "#             else:\n",
    "#                  self.take_profit= fill_price + action * self.risk\n",
    "#                  self.stop_loss= fill_price - action * self.risk \n",
    "\n",
    "#         else:   #Swing mode\n",
    "#             if action == 1:\n",
    "#                 low_data = self.price_data['low'][:current_index + 1]\n",
    "#                 swing_low_indices = argrelextrema(np.array(low_data), lambda x, y: x < y, order=self.scipy_neighborhood, )[0]\n",
    "#                 try:\n",
    "#                     self.stop_loss = low_data[next(x for x in swing_low_indices[::-1] if low_data[x] < fill_price)]\n",
    "#                 except: \n",
    "#                     self.stop_loss = fill_price - minimum_risk\n",
    "#                 self.risk = abs(self.stop_loss - fill_price)\n",
    "#                 self.take_profit = fill_price + self.risk * self.R2R\n",
    "\n",
    "#             else:\n",
    "#                 high_data = self.price_data['high'][:current_index+1]\n",
    "#                 swing_high_indices = argrelextrema(np.array(high_data), lambda x, y: x > y, order=self.scipy_neighborhood)[0]\n",
    "#                 try:\n",
    "#                     self.stop_loss =  high_data[next(x for x in swing_high_indices[::-1] if high_data[x] > fill_price)]\n",
    "#                 except:\n",
    "#                     self.stop_loss = fill_price + minimum_risk\n",
    "#                 self.risk = abs(self.stop_loss - fill_price)\n",
    "#                 self.take_profit = fill_price - self.risk * self.R2R\n",
    "\n",
    "#     '''\n",
    "#     func to step action on environment \n",
    "\n",
    "#     '''\n",
    "#     def step(self, action):\n",
    "        \n",
    "#         doned_action = int(action) - 1    # action space should be in (-1,0,1)\n",
    "#         reward=0\n",
    "#         self.price_data.loc[self.current_point,'action']= doned_action\n",
    "#         # last_action = (self.tradeslist)['action'][len(self.tradeslist)-1]\n",
    "#         done = 0\n",
    "#         close_price = self.get_price(self.current_point)\n",
    "\n",
    "#         if (self.day_index < len(self.day_indices)-1 and self.current_point == self.day_indices[self.day_index+1] -1 ) or \\\n",
    "#                 self.current_point == len(self.data) - 2:\n",
    "#             done = 1 \n",
    "\n",
    "#         if  (doned_action!=0 and self.sltp_flag):\n",
    "\n",
    "#             self.calculate_sltp(self.current_point,doned_action,close_price)\n",
    "#             self.sltp_flag= False\n",
    "\n",
    "#         profit_loss, MAE, MPE = self.calculate_reward(self.last_action,doned_action, self.current_point,self.entry_index)\n",
    "  \n",
    "#         if profit_loss and self.last_action!= doned_action:\n",
    "            \n",
    "#             if profit_loss > 0:\n",
    "#                 self.positives += profit_loss\n",
    "#             else:\n",
    "#                 self.negatives += profit_loss\n",
    "#             self.account += profit_loss\n",
    "\n",
    "       \n",
    "#         if (doned_action!=0 and self.last_action!= doned_action) :\n",
    "          \n",
    "#             #print('sl: ',self.stop_loss,'tp: ',self.take_profit,'action: ',self.last_action)\n",
    "#             self.tradeslist.loc[len(self.tradeslist)] = [self.entry_date, self.get_price(self.entry_index),\n",
    "#                                                         self.last_action, self.get_date(),\n",
    "#                                                         self.get_price(self.current_point), profit_loss,self.account, MAE,\n",
    "#                                                         MPE,'reverse',self.stop_loss,self.take_profit]\n",
    "#             self.entry_index = self.current_point\n",
    "#             self.entry_date = self.get_date()\n",
    "#             self.calculate_sltp(self.current_point,doned_action,close_price)\n",
    "#             self.last_action= doned_action\n",
    "#             #self.sltp_flag= False\n",
    "            \n",
    "#         elif (self.last_action== 1  and (close_price>= self.take_profit or close_price<= self.stop_loss)) or (self.last_action== -1 and (close_price<= self.take_profit or close_price>= self.stop_loss)):\n",
    "#                 #print('action:',doned_action,'close:',close_price,'sl:',self.stop_loss,'tp:',self.take_profit)\n",
    "#                 self.tradeslist.loc[len(self.tradeslist)] = [self.entry_date, self.get_price(self.entry_index),\n",
    "#                                                             self.last_action, self.get_date(),\n",
    "#                                                             self.get_price(self.current_point), profit_loss,self.account, MAE,\n",
    "#                                                             MPE,'sltp',self.stop_loss,self.take_profit]\n",
    "#                 self.entry_index = self.current_point\n",
    "#                 self.entry_date = self.get_date()\n",
    "#                 self.last_action= doned_action\n",
    "#                 self.sltp_flag= True\n",
    "        \n",
    "#         self.current_position = doned_action\n",
    "        \n",
    "#         if self.account <= 0:\n",
    "#             done = 1\n",
    "            \n",
    "#         self.current_point += 1\n",
    "       \n",
    "#         s_ = self.get_state()\n",
    "      \n",
    "#         return s_, float(reward), done, {\"account_status\":self.account}\n",
    "\n",
    "#     '''\n",
    "#     func to reset environment\n",
    "\n",
    "#     '''\n",
    "#     def reset(self):\n",
    "\n",
    "#         self.positives = 0\n",
    "#         self.negatives = 0\n",
    "#         self.day_index +=1\n",
    "#         self.current_point = self.day_indices[self.day_index]\n",
    "    \n",
    "#         #self.make_plot() # plot result at the end of each day(episode)\n",
    "#         self.episode += 1\n",
    "       \n",
    "#         self.current_position = 0\n",
    "#         self.entry_index = self.current_point\n",
    "\n",
    "#         return self.get_state()\n",
    "\n",
    "#     '''\n",
    "#     func to ?\n",
    "\n",
    "#     '''\n",
    "#     def _seed(self, seed=None):     # we want to start with same arameters each time\n",
    "#         self.np_random, seed = seeding.np_random(seed)\n",
    "#         return [seed]\n",
    "        \n",
    "#     '''\n",
    "#     func to ?\n",
    "\n",
    "#     '''\n",
    "#     def get_sb_env(self):     \n",
    "#         e = DummyVecEnv([lambda: self])\n",
    "#         obs = e.reset()\n",
    "#         return e, obs\n",
    "\n",
    "\n",
    "#     '''\n",
    "#     func to plot result\n",
    "\n",
    "#     '''\n",
    "#     def make_plot(self):\n",
    "#         plt.plot(self.tradeslist['pnl'], 'g')   # plot PNL from trade list\n",
    "#         plt.savefig('results/PNL.png')      # save plot as png\n",
    "#         plt.close()\n",
    "    \n",
    "#     '''\n",
    "#     func to save actions that has been taken on each step\n",
    "\n",
    "#     '''\n",
    "#     def trade_history(self):\n",
    "\n",
    "#         self.price_data.to_csv('actiones_taked.csv')\n",
    "\n",
    "#         return self.tradeslist\n",
    "\n",
    "\n",
    "#     '''\n",
    "#     func to get results of backtesting\n",
    "\n",
    "#     '''\n",
    "#     def show_results(self):\n",
    "\n",
    "#         results= self.tradeslist.copy()\n",
    "#         #results['cum_pnl'] = results['pnl'].cumsum()\n",
    "#         initial_balance= self.base_account\n",
    "       \n",
    "#         cagr_dd = -20\n",
    "#         pf = 0\n",
    "#         pessimistic_return_on_margin = -10\n",
    "#         if len(results):\n",
    "#             pos = np.sum(results['pnl'][results['pnl'] > 0])\n",
    "#             neg = np.sum(results['pnl'][results['pnl'] < 0])\n",
    "#             long_num = len(results['action'][results['action'] == 1])\n",
    "#             short_num = len(results['action'][results['action'] == -1])\n",
    "#             cagr = float(results['cum_pnl'][-1:])\n",
    "#             max_drawdown = np.min(\n",
    "#                 results['cum_pnl'] - results['cum_pnl'].rolling(len(results), min_periods=1).max())\n",
    "#             mean_drawdown = -np.mean(\n",
    "#                 results['cum_pnl'] - results['cum_pnl'].rolling(len(results), min_periods=1).max())\n",
    "#             cagr_dd = cagr / mean_drawdown if mean_drawdown != 0 else cagr\n",
    "#             pf = pos / -neg if neg else np.sum(results['pnl'] > 0)\n",
    "#             margin = 50\n",
    "#             average_win = 0\n",
    "#             average_loss = 0\n",
    "#             winning_trades = len(results[results['pnl'] > 0].index)\n",
    "#             losing_trades = len(results[results['pnl'] < 0].index)\n",
    "#             if winning_trades:\n",
    "#                 average_win = pos / winning_trades\n",
    "#             if losing_trades:\n",
    "#                 average_loss = - neg / losing_trades\n",
    "#             adjusted_num_of_wins = winning_trades - winning_trades ** .5\n",
    "#             adjusted_num_of_losses = losing_trades + losing_trades ** .5\n",
    "#             adjusted_profit = average_win * adjusted_num_of_wins\n",
    "#             adjusted_loss = average_loss * adjusted_num_of_losses\n",
    "#             pessimistic_return_on_margin = (adjusted_profit - adjusted_loss) / margin\n",
    "#             print(tabulate(\n",
    "#                 {\"long#\":[long_num], \"short#\":[short_num], \"Cumulative PnL\": [cagr], \"PROM\": [pessimistic_return_on_margin],\n",
    "#                 \"Profit factor\": [pf], \"max drawdown\": [max_drawdown], \"PnLs\": {str(pos) + ' ' + str(neg)}}, headers=\"keys\", tablefmt=\"grid\"))\n",
    "                \n",
    "#             plt.figure(figsize=(9,6))\n",
    "#             plt.plot(results['exit date'],results['cum_pnl'] , color ='green', markersize=4)\n",
    "#             plt.grid()\n",
    "#             plt.ylabel('Point', labelpad = 8, fontsize = 14)\n",
    "#             plt.xlabel('Dates', labelpad = 8, fontsize = 14)\n",
    "#             plt.xticks(rotation=90)\n",
    "#             plt.savefig('results/PNL.png') \n",
    "#             plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1af19bf6d9b6220b63f9c4301657dd2793b9b571811340b99da04e342a11312b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
